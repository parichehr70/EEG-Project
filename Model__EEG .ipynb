{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5CE-YMCa71C",
    "outputId": "e78b85c1-a42b-4f36-a7aa-f0269dc332b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWy0ksRxofbh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EDLmqJTcLaM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "dataDir = \"/content/drive/MyDrive/data_preprocessed_matlab/\"\n",
    "mats = []\n",
    "for file in os.listdir(dataDir) :\n",
    "    mats.append(scipy.io.loadmat(dataDir+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "an6gT2i9HqVG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in range(len(mats)):\n",
    "  mats[i]=pd.Series(mats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFAexTLPHhoq"
   },
   "outputs": [],
   "source": [
    "for i in range(len(mats)):\n",
    "  mats[i]=mats[i].drop(['__header__','__version__','__globals__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEezHZjLKAhc",
    "outputId": "2070243e-6975-4dc7-a906-6a0e331b42a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (40, 40, 8064) (40, 4)\n",
      "1 (40, 40, 8064) (40, 4)\n",
      "2 (40, 40, 8064) (40, 4)\n",
      "3 (40, 40, 8064) (40, 4)\n",
      "4 (40, 40, 8064) (40, 4)\n",
      "5 (40, 40, 8064) (40, 4)\n",
      "6 (40, 40, 8064) (40, 4)\n",
      "7 (40, 40, 8064) (40, 4)\n",
      "8 (40, 40, 8064) (40, 4)\n",
      "9 (40, 40, 8064) (40, 4)\n",
      "10 (40, 40, 8064) (40, 4)\n",
      "11 (40, 40, 8064) (40, 4)\n",
      "12 (40, 40, 8064) (40, 4)\n",
      "13 (40, 40, 8064) (40, 4)\n",
      "14 (40, 40, 8064) (40, 4)\n",
      "15 (40, 40, 8064) (40, 4)\n",
      "16 (40, 40, 8064) (40, 4)\n",
      "17 (40, 40, 8064) (40, 4)\n",
      "18 (40, 40, 8064) (40, 4)\n",
      "19 (40, 40, 8064) (40, 4)\n",
      "20 (40, 40, 8064) (40, 4)\n",
      "21 (40, 40, 8064) (40, 4)\n",
      "22 (40, 40, 8064) (40, 4)\n",
      "23 (40, 40, 8064) (40, 4)\n",
      "24 (40, 40, 8064) (40, 4)\n",
      "25 (40, 40, 8064) (40, 4)\n",
      "26 (40, 40, 8064) (40, 4)\n",
      "27 (40, 40, 8064) (40, 4)\n",
      "28 (40, 40, 8064) (40, 4)\n",
      "29 (40, 40, 8064) (40, 4)\n",
      "30 (40, 40, 8064) (40, 4)\n",
      "31 (40, 40, 8064) (40, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(mats)):\n",
    "  print(i,mats[i]['data'].shape,mats[i]['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzKf52FBQMZ2"
   },
   "outputs": [],
   "source": [
    "B1 = np.load('/content/drive/MyDrive/B1.npy')\n",
    "B2 = np.load('/content/drive/MyDrive/B2.npy')\n",
    "B3 = np.load('/content/drive/MyDrive/B3.npy')\n",
    "B4 = np.load('/content/drive/MyDrive/B4.npy')\n",
    "B5 = np.load('/content/drive/MyDrive/B5.npy')\n",
    "B6 = np.load('/content/drive/MyDrive/B6.npy')\n",
    "B7 = np.load('/content/drive/MyDrive/B7.npy')\n",
    "B8 = np.load('/content/drive/MyDrive/B8.npy')\n",
    "B9 = np.load('/content/drive/MyDrive/B9.npy')\n",
    "B10 = np.load('/content/drive/MyDrive/B10.npy')\n",
    "B11 = np.load('/content/drive/MyDrive/B11.npy')\n",
    "B12 = np.load('/content/drive/MyDrive/B12.npy')\n",
    "B13 = np.load('/content/drive/MyDrive/B13.npy')\n",
    "B14 = np.load('/content/drive/MyDrive/B14.npy')\n",
    "B15 = np.load('/content/drive/MyDrive/B15.npy')\n",
    "B16 = np.load('/content/drive/MyDrive/B16.npy')\n",
    "B17 = np.load('/content/drive/MyDrive/B17.npy')\n",
    "B18 = np.load('/content/drive/MyDrive/B18.npy')\n",
    "B19 = np.load('/content/drive/MyDrive/B19.npy')\n",
    "B20 = np.load('/content/drive/MyDrive/B20.npy')\n",
    "B21 = np.load('/content/drive/MyDrive/B21.npy')\n",
    "B22 = np.load('/content/drive/MyDrive/B22.npy')\n",
    "B23 = np.load('/content/drive/MyDrive/B23.npy')\n",
    "B24 = np.load('/content/drive/MyDrive/B24.npy')\n",
    "B25 = np.load('/content/drive/MyDrive/B25.npy')\n",
    "B26 = np.load('/content/drive/MyDrive/B26.npy')\n",
    "B27 = np.load('/content/drive/MyDrive/B27.npy')\n",
    "B28 = np.load('/content/drive/MyDrive/B28.npy')\n",
    "B29 = np.load('/content/drive/MyDrive/B29.npy')\n",
    "B30 = np.load('/content/drive/MyDrive/B30.npy')\n",
    "B31 = np.load('/content/drive/MyDrive/B31.npy')\n",
    "B32 = np.load('/content/drive/MyDrive/B32.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFGTCZLFGX8g"
   },
   "outputs": [],
   "source": [
    "B1.resize(40*8064,9,9)\n",
    "B2.resize(40*8064,9,9)\n",
    "B3.resize(40*8064,9,9)\n",
    "B4.resize(40*8064,9,9)\n",
    "B5.resize(40*8064,9,9)\n",
    "B6.resize(40*8064,9,9)\n",
    "B7.resize(40*8064,9,9)\n",
    "B8.resize(40*8064,9,9)\n",
    "B9.resize(40*8064,9,9)\n",
    "B10.resize(40*8064,9,9)\n",
    "B11.resize(40*8064,9,9)\n",
    "B12.resize(40*8064,9,9)\n",
    "B13.resize(40*8064,9,9)\n",
    "B14.resize(40*8064,9,9)\n",
    "B15.resize(40*8064,9,9)\n",
    "B16.resize(40*8064,9,9)\n",
    "B17.resize(40*8064,9,9)\n",
    "B18.resize(40*8064,9,9)\n",
    "B19.resize(40*8064,9,9)\n",
    "B20.resize(40*8064,9,9)\n",
    "B21.resize(40*8064,9,9)\n",
    "B22.resize(40*8064,9,9)\n",
    "B23.resize(40*8064,9,9)\n",
    "B24.resize(40*8064,9,9)\n",
    "B25.resize(40*8064,9,9)\n",
    "B26.resize(40*8064,9,9)\n",
    "B27.resize(40*8064,9,9)\n",
    "B28.resize(40*8064,9,9)\n",
    "B29.resize(40*8064,9,9)\n",
    "B30.resize(40*8064,9,9)\n",
    "B31.resize(40*8064,9,9)\n",
    "B32.resize(40*8064,9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yc6x7854vBQj"
   },
   "outputs": [],
   "source": [
    "label1 = mats[0][0]\n",
    "label2 = mats[1][0]\n",
    "label3 = mats[2][0]\n",
    "label4 = mats[3][0]\n",
    "label5 = mats[4][0]\n",
    "label6 = mats[5][0]\n",
    "label7 = mats[6][0]\n",
    "label8 = mats[7][0]\n",
    "label9 = mats[8][0]\n",
    "label10 = mats[9][0]\n",
    "label11 = mats[10][0]\n",
    "label12 = mats[11][0]\n",
    "label13 = mats[12][0]\n",
    "label14 = mats[13][0]\n",
    "label15 = mats[14][0]\n",
    "label16 = mats[15][0]\n",
    "label17 = mats[16][0]\n",
    "label18 = mats[17][0]\n",
    "label19 = mats[18][0]\n",
    "label20 = mats[19][0]\n",
    "label21 = mats[20][0]\n",
    "label22 = mats[21][0]\n",
    "label23 = mats[22][0]\n",
    "label24 = mats[23][0]\n",
    "label25 = mats[24][0]\n",
    "label26 = mats[25][0]\n",
    "label27 = mats[26][0]\n",
    "label28 = mats[27][0]\n",
    "label29 = mats[28][0]\n",
    "label30 = mats[29][0]\n",
    "label31 = mats[30][0]\n",
    "label32 = mats[31][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoj1fmltJprS"
   },
   "outputs": [],
   "source": [
    "label1 = np.repeat(label1, repeats=8064, axis=0)\n",
    "label2 = np.repeat(label2, repeats=8064, axis=0)\n",
    "label3 = np.repeat(label3, repeats=8064, axis=0)\n",
    "label4 = np.repeat(label4, repeats=8064, axis=0)\n",
    "label5 = np.repeat(label5, repeats=8064, axis=0)\n",
    "label6 = np.repeat(label6, repeats=8064, axis=0)\n",
    "label7 = np.repeat(label7, repeats=8064, axis=0)\n",
    "label8 = np.repeat(label8, repeats=8064, axis=0)\n",
    "label9 = np.repeat(label9, repeats=8064, axis=0)\n",
    "label10 = np.repeat(label10, repeats=8064, axis=0)\n",
    "label11 = np.repeat(label11, repeats=8064, axis=0)\n",
    "label12 = np.repeat(label12, repeats=8064, axis=0)\n",
    "label13 = np.repeat(label13, repeats=8064, axis=0)\n",
    "label14 = np.repeat(label14, repeats=8064, axis=0)\n",
    "label15 = np.repeat(label15, repeats=8064, axis=0)\n",
    "label16 = np.repeat(label16, repeats=8064, axis=0)\n",
    "label17 = np.repeat(label17, repeats=8064, axis=0)\n",
    "label18 = np.repeat(label18, repeats=8064, axis=0)\n",
    "label19 = np.repeat(label19, repeats=8064, axis=0)\n",
    "label20 = np.repeat(label20, repeats=8064, axis=0)\n",
    "label21 = np.repeat(label21, repeats=8064, axis=0)\n",
    "label22 = np.repeat(label22, repeats=8064, axis=0)\n",
    "label23 = np.repeat(label23, repeats=8064, axis=0)\n",
    "label24 = np.repeat(label24, repeats=8064, axis=0)\n",
    "label25 = np.repeat(label25, repeats=8064, axis=0)\n",
    "label26 = np.repeat(label26, repeats=8064, axis=0)\n",
    "label27 = np.repeat(label27, repeats=8064, axis=0)\n",
    "label28 = np.repeat(label28, repeats=8064, axis=0)\n",
    "label29 = np.repeat(label29, repeats=8064, axis=0)\n",
    "label30 = np.repeat(label30, repeats=8064, axis=0)\n",
    "label31 = np.repeat(label31, repeats=8064, axis=0)\n",
    "label32 = np.repeat(label32, repeats=8064, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UD4g2cMHgMY3"
   },
   "outputs": [],
   "source": [
    "X = [B1, B2, B3, B4, B5, B6, B7, B8, B9, B10, B11, B12, B13, B14, B15, B16, B17, B18, B19, B20, B21, B22, B23, B24, B25, B26, B27, B28, B29, B30, B31, B32]\n",
    "y = [label1, label2, label3, label4, label5, label6, label7, label8, label9, label10, label11, label12, label13, label14, label15, label16,\n",
    "     label17, label18, label19, label20, label21, label22, label23, label24, label25, label26, label27, label28, label29, label30, label31, label32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDQm6ILUSQqN"
   },
   "outputs": [],
   "source": [
    "import os, math, random, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "from __future__ import print_function, division\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFQGHzfFNUit"
   },
   "outputs": [],
   "source": [
    "def timer_start():\n",
    "    global t0\n",
    "    t0 = time.time()\n",
    "    \n",
    "def timer_end():   \n",
    "    print('Time elapsed {:0.1f}s'.format(time.time() - t0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMyqcqPjNq_f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0625, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTPG9IikRG4_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(X_train, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(X_test, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgipbOCCBO1y"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(8064, 256, kernel_size=(3,3), stride=(1,1), padding=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(256, 128, kernel_size=(3,3), stride=(1, 1), padding=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=(3,3), stride=(1, 1), padding=(2, 2))\n",
    "        self.conv4 = nn.Conv2d(64, 32, kernel_size=(3,3), stride=(1, 1), padding=(2, 2))\n",
    "        self.conv5 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=(1, 1), padding=(2, 2))\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 17 * 17, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.flat(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = nn.Dropout(p=0.3)(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x),dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1r8y6GImKUUa"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bJp2Vs4I20e"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "print('Device: ',device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yX6HzwXAKjrx"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, train_loader, optimizer, criterion) :   \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(X_train, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        epoch_loss += outputs.shape[0] * loss.item()\n",
    "    epoch_loss = epoch_loss / len(X_train)\n",
    "    return epoch_loss\n",
    "\n",
    "def test(model, epoch, test_loader, optimizer, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(X_test, 0):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) \n",
    "            epoch_loss += outputs.shape[0] * loss.item()\n",
    "    epoch_loss = epoch_loss / len(X_test)\n",
    "    return epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE=16\n",
    "num_batches = math.ceil(len(X_train) / BATCH_SIZE)\n",
    "\n",
    "print('Number of Training samples {}, Batch Size {}, Num Batch {}'.format(len(X_train), BATCH_SIZE, num_batches ))\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "for epoch in range( EPOCHS):  \n",
    "    timer_start()\n",
    "    print('[Epoch {} of {}]'.format(epoch +1, EPOCHS), end = ' ')\n",
    "    tr_loss = train(model, epoch, X_train, optimizer, criterion)\n",
    "    val_loss = test(model, epoch, X_test, optimizer, criterion)  \n",
    "    timer_end()\n",
    "    print('tr_loss: {:0.4f}| val_loss {:0.4f}'.format(tr_loss , val_loss))\n",
    "    history['epoch'].append(epoch+1)\n",
    "    history['tr_loss'].append(round(tr_loss,5))\n",
    "    history['val_loss'].append(round(val_loss,5))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_EEG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
